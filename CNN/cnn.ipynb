{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "from time import sleep\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data():\n",
    "    \"\"\"\n",
    "    Loads data\n",
    "    \"\"\"\n",
    "    files = [\"rt-polarity.neg\", \"rt-polarity.pos\"]\n",
    "    revs = []\n",
    "    vocab = defaultdict(float)\n",
    "    max_l = 0\n",
    "    for i in range(2):\n",
    "        with open(files[i], \"r\", encoding=\"cp1252\") as f:\n",
    "            for line in f:\n",
    "                orig_rev = clean_str(line.strip())\n",
    "                words = set(orig_rev.split())\n",
    "                for word in words:\n",
    "                    vocab[word] += 1\n",
    "                datum  = {  \"y\":i,\n",
    "                            \"text\": orig_rev}\n",
    "                if len(orig_rev.split()) > max_l:\n",
    "                    max_l = len(orig_rev.split())\n",
    "                revs.append(datum)\n",
    "    return revs, vocab, max_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bin_vec(fname, vocab):\n",
    "    \"\"\"\n",
    "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
    "    \"\"\"\n",
    "    word_vecs = {}\n",
    "    with open(fname, \"rb\") as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, layer1_size = map(int, header.split())  # 3000000, 300\n",
    "        binary_len = 4 * layer1_size\n",
    "        for line in tqdm_notebook(range(vocab_size), desc='load_bin_vec'):\n",
    "            word = []\n",
    "            while True:\n",
    "                ch = f.read(1).decode(\"latin1\")\n",
    "                if ch == ' ':\n",
    "                    word = ''.join(word)\n",
    "                    break\n",
    "                if ch != '\\n':\n",
    "                    word.append(ch)\n",
    "            if word in vocab:\n",
    "                word_vecs[word] = torch.from_numpy(np.frombuffer(f.read(binary_len), dtype='float32'))\n",
    "            else:\n",
    "                f.read(binary_len)\n",
    "    return word_vecs, layer1_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=56, k=300):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l:\n",
    "        x.append(0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_idx_data(revs, word_idx_map, max_l=56, k=300):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_x_idx, train_y, test_x_idx, test_y = [], [], [], []\n",
    "    random.shuffle(revs)\n",
    "    for rev, i in zip(revs, range(len(revs))):\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k)\n",
    "        if i < len(revs) / 10:\n",
    "            test_x_idx.append(sent)\n",
    "            test_y.append(rev[\"y\"])\n",
    "        else:\n",
    "            train_x_idx.append(sent)\n",
    "            train_y.append(rev[\"y\"])\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    return train_x_idx, train_y, test_x_idx, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data... data loaded!\n",
      "number of sentences: 10662\n",
      "vocab size: 18764\n",
      "max sentence length: 56\n"
     ]
    }
   ],
   "source": [
    "# read MR dataset\n",
    "print(\"loading data...\", end=' ')\n",
    "revs, vocab, max_l = build_data()\n",
    "print(\"data loaded!\")\n",
    "\n",
    "print(\"number of sentences: \" + str(len(revs)))             # 10662\n",
    "print(\"vocab size: \" + str(len(vocab)))                     # 18764\n",
    "print(\"max sentence length: \" + str(max_l))                 # 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word2vec vectors... "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeedc8f4f4d8446e93c3e10bfd3025fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='load_bin_vec', max=3000000, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "word2vec loaded!\n",
      "num words already in word2vec: 16448\n"
     ]
    }
   ],
   "source": [
    "# read pre-trained word2vec\n",
    "print(\"loading word2vec vectors...\", end=' ')\n",
    "word_vecs, k = load_bin_vec(\"GoogleNews-vectors-negative300.bin\", vocab)\n",
    "print(\"word2vec loaded!\")\n",
    "\n",
    "print(\"num words already in word2vec: \" + str(len(word_vecs)))    # 16448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset created!\n"
     ]
    }
   ],
   "source": [
    "# Embedding layer\n",
    "embedding = nn.Embedding(len(vocab)+1, k, padding_idx=0)\n",
    "W = {}\n",
    "word_idx_map = {}\n",
    "W[\"rand\"] = W[\"vec\"] = embedding(torch.LongTensor(range(len(vocab)+1))) # torch.Size([18765, 300])\n",
    "for word, i in zip(vocab, range(1,len(vocab)+1)):\n",
    "    if word in word_vecs:\n",
    "        W[\"vec\"][i] = word_vecs[word]\n",
    "    word_idx_map[word] = i\n",
    "print(\"dataset created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(x_idx, W, max_l=56, k=300):\n",
    "    x = torch.Tensor(len(x_idx), 1, max_l * k)\n",
    "    for i, sent in enumerate(x_idx):\n",
    "        xx = []\n",
    "        for idx in sent:\n",
    "            xx.append(W[idx])\n",
    "        x[i] = torch.cat(tuple(xx))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, hs, feature, k, p):\n",
    "        super(CNN, self).__init__()\n",
    "        for h in hs:\n",
    "            conv = nn.Conv1d(1, feature, h * k, stride=k)\n",
    "            setattr(self, 'conv%d' % h, conv)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.drop = nn.Dropout(p)\n",
    "        self.fc = nn.Linear(len(hs) * feature, 2)\n",
    "        self.loss = nn.LogSoftmax(dim=-1)\n",
    "        self.hs = hs\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for h in self.hs:\n",
    "            conv = getattr(self, 'conv%d' % h)\n",
    "            out = self.drop(self.relu(conv(x)))\n",
    "            out = self.pool(out)\n",
    "            outs.append(out)\n",
    "        outs = torch.cat(outs, dim=1).reshape(-1, 300)\n",
    "        outs = self.fc(outs)\n",
    "        return self.loss(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_trainer(train_loader, test_x, test_y, W, non_static, h=[3,4,5], feature=100, p=0.5, s=3, k=300):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = CNN(h, feature, k, p)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in tqdm_notebook(range(10), desc='epoch'):\n",
    "        total_loss = 0\n",
    "        for train_x, train_y in tqdm_notebook(train_loader, desc='train', leave=False):\n",
    "            train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_x)\n",
    "            loss = criterion(output, train_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(epoch+1, total_loss)\n",
    "        \n",
    "    test_x, test_y = Variable(test_x), Variable(test_y)\n",
    "    result = torch.max(model(test_x).data, 1)[1]\n",
    "    accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354e02b3777643e29dd9233a6950d5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='i', max=3, style=ProgressStyle(description_width='initial')),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d6d77d422d4f1a87f5cb8cbaf11731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=10, style=ProgressStyle(description_width='initiaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor(134.5587)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tensor(129.9518)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tensor(127.1918)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 tensor(124.6030)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 tensor(121.3380)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 tensor(117.8803)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 tensor(114.5540)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 tensor(110.5532)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 tensor(107.5446)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='train', max=192, style=ProgressStyle(description_width='initiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 tensor(104.4133)\n"
     ]
    }
   ],
   "source": [
    "non_static = [True, False, True]\n",
    "U = [\"rand\", \"vec\", \"vec\"]\n",
    "accuracies = []\n",
    "train_x_idx, train_y, test_x_idx, test_y = make_idx_data(revs, word_idx_map, max_l=max_l, k=300)    # 9595 1067 X 56\n",
    "for i in tqdm_notebook(range(3), desc='i'):\n",
    "    train_x = make_data(train_x_idx, W[U[i]], max_l=max_l, k=300) # 9595, 1, 16800\n",
    "    test_x = make_data(test_x_idx, W[U[i]], max_l=max_l, k=300)\n",
    "    train = TensorDataset(train_x, train_y)\n",
    "    train_loader = DataLoader(train, batch_size=50)\n",
    "    accuracy = cnn_trainer(train_loader, test_x, test_y, W[U[i]], non_static[i], h=[3,4,5], feature=100, p=0.5, s=3, k=300)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
